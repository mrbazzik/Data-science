find.packages("devtools")
install.packages("devtools")
find.packages("devtools")
find.package("devtools")
library(devtools)
library(devtools)
find_rtools()
install.package("KernSmooth")
install.packages("KernSmooth")
library(KernSmooth)
x = c(2,7,5)
x
y=seq(from=4, length=3,by=3)
y
x+y
x*y
x/y
x^y
x[2]
x[2:3]
x[-2]
x[-2:]
x[-c(1,2)]
x
z=matrix(se(1,12),4,3)
z=matrix(seq(1,12),4,3)
z
z[3:4,1:2]
z[,1:2]
z[,1]
z[,1,drop=FALSE]
dim(z)
p = z[,1,drop=FALSE]
dim(p)
p[0]
p[1]
p[1,1]
p[1,2]
p[2,1]
p[2]
ls()
runit(50)
runif(50)
rnorm(50)
x = runif(50)
y = rnorm(50)
plot(x,y)
plot(x,y,rlab="Uniform",ylab="Normal",pch="+",col="blue")
plot(x,y,xlab="Uniform",ylab="Normal",pch="+",col="blue")
plot(x,y,xlab="Uniform",ylab="Normal",pch="0",col="blue")
plot(x,y,xlab="Uniform",ylab="Normal",pch="d",col="blue")
par(mfrow=c(2,1))
plot(x,y)
hist(y)
hist(y)
plot(x,y)
df = read.csv('c:\Users\Basov_il\Documents\GitHub\ML-tasks\Titanic\train_data\train.csv')
df = read.csv("c:\Users\Basov_il\Documents\GitHub\ML-tasks\Titanic\train_data\train.csv")
df = read.csv("c:\\Users\\Basov_il\\Documents\\GitHub\\ML-tasks\\Titanic\\train_data\\train.csv")
names(df)
dim(df)
class(df)
summary(df)
info(df)
describe(df)
df.info()
str(df)
plot(df$Age,df$Survived)
par(mfrow=c(1,1))
plot(df$Age,df$Survived)
hist(df$Age)
attach(df)
ls()
Age
df = read.csv('c:\\Users\\Basov_il\\Documents\\GitHub\\ML-tasks\\Titanic\\train_data\\train.csv')
names(df)
?df
attach(df)
plot(Age~Pclass)
rm(df)
df = read.csv('c:\\Users\\Basov_il\\Documents\\GitHub\\ML-tasks\\Titanic\\train_data\\train.csv')
plot(Age~Pclass,df)
plot(SibSp~Age,df)
plot(Fare~Age,df)
?lm
fit1=lm(Fare~Age, data=df)
fit1
summary(fit1)
abline(fit1,col="red"")
plot(Fare~Age,df)
plot(Fare~Age,df)
abline(fit1,col="red"")
abline(fit1,col="red")
abline(fit1,col="red")
names(fit1)
confint(fit1)
predict(fit1,data.frame(Age=c(20,40,60)))
predict(fit1,data.frame(Age=c(20,40,60)),interval='confidence')
fit2 = lm(Fare~Age+Pclass,df)
summary(fit2)
fit3 = lm(Survived~.,df)
summary(fit3)
fit5 = lm(Fare~Pclass*Age,df)
summary(fit5)
fit6=lm(Fare~Pclass+I(Pclass^2).df)
fit6=lm(Fare~Pclass+I(Pclass^2),df)
summary(fit6)
plot(Fare~Pclass)
points(Pclass,fitted(fit6), col='red',pch=20)
fit7=lm(Fare~poly(Pclass,4))
fit7=lm(Fare~poly(Pclass,3))
fit7=lm(Fare~poly(Age,4))
df = read.csv('c:\\Users\\Basov_il\\Documents\\GitHub\\ML-tasks\\Titanic\\train_data\\train.csv')
pairs(df,col=df$Survived)
pairs(df,col=df$Survived)
library(httr)
myapp = oath_app("github", key="3d85279fccdfe5f3145c", secret="4feed86faefecc5f62fcb112f6ce2a9a986dac9c")
myapp = oauth_app("github", key="3d85279fccdfe5f3145c", secret="4feed86faefecc5f62fcb112f6ce2a9a986dac9c")
sig = sign(myapp)
sig = sign_oauth1.0(myapp)
test = GET("https://api.github.com/users/jtleek/repos", sig)
test = GET("https://api.github.com/users/jtleek/repos", myapp)
sig = sign_oauth1.0(myapp,token="0643a5aefa5e19c7701fbe1a57a69e389fbc9d53")
test = GET("https://api.github.com/users/jtleek/repos", sig)
install.packages('base64enc')
test = GET("https://api.github.com/users/jtleek/repos", sig)
test
oauth_endpoints("github")
github_token <- oauth1.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
1
install.packages('httpuv')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
test = GET("https://api.github.com/users/jtleek/repos", config(token=github_token))
test
github_token
setwd("c:\Users\Basov_il\Documents\GitHub\Data-science\")
setwd("c:\\Users\\Basov_il\\Documents\\GitHub\\Data-science\\")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="ACS.csv")
df <- read.csv("ACS.csv")
str(df)
names <- strsplit(names(df),"wgtp")
names[123]
names(df)[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv ", destfile="FGDP.csv")
df <- read.csv("FGDP.csv")
str(df)
head(df$X.3,10)
?gsub
amounts<-as.numeric(gsub(",","",df$X.3))
amounts
mean(amounts, rm.na=TRUE)
?mean
mean(amounts, na.rm=TRUE)
df$X.3
df <- read.csv("FGDP.csv", skip=10)
str(df)
df <- read.csv("FGDP.csv", skip=4)
str(df)
levels(df$X.1)
df <- read.csv("FGDP.csv", skip=5)
str(df)
df <- read.csv("FGDP.csv", skip=3)
str(df)
df <- read.csv("FGDP.csv", skip=2)
str(df)
df <- read.csv("FGDP.csv", skip=3)
str(df)
df <- read.csv("FGDP.csv", skip=2)
str(df)
df <- read.csv("FGDP.csv", skip=4)
str(df)
df <- read.csv("FGDP.csv", skip=4, stringsAsFactors=FALSE)
str(df)
unique(df$X.1)
df$X.1 <- as.numeric(df$X.1)
unique(df$X.1)
length(unique(df$X.1))
df <- df[!is.na(df$X.1),]
str(df)
length(unique(df$X.1))
unique(df$X.1)
amounts <- gsub(",","",df$X.4)
length(amounts)
amounts<-as.numeric(amounts)
sum(is.na(amounts))
table(df$X.1)
mean(amounts)
grep("^United",df$X.3)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="ED.csv")
ed <- read.csv("ED.csv")
str(ed)
ed <- read.csv("ED.csv", stringsAsFactors=FALSE)
str(ed)
unique(ed$CountryCode)
length(unique(ed$CountryCode))
ds<-merge(df,ed,by.x="X", by.y="CountryCode")
df[df$x.1==178,]
df[df$X.1==178,]
length(unique(df$X))
length(unique(ds$X))
str(ds)
str(ed)
grep("Fiscal year end:.*?[Jj]un[e]?", ds$Special.Notes)
grep("Fiscal year end:.*?[Jj]un[e]?", ds$Special.Notes, value=TRUE)
length(grep("Fiscal year end:.*?[Jj]un[e]?", ds$Special.Notes))
library(quantmod)
install.packages(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
class(sampleTimes[0])
head(format(sampleTimes,"%Y"))
sum(format(sampleTimes,"%Y")=="2012")
head(format(sampleTimes,"%a"))
head(format(sampleTimes,"%A"))
sum(format(sampleTimes,"%a")=="Пн")
head(format(sampleTimes,"%a")=="Пн")
head(format(sampleTimes,"%a-%Y"))
sum(format(sampleTimes,"%a-%Y")=="Пн-2012")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
sqirl()
swirl()
mydf<-read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id,package,country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package=="swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux_gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran, ip_id,package, size)
cran3
mutate(cran3, size_mb = size/2^20)
mutate(cran3, size_mb = size/2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes=,mean(size))
summarize(cran, avg_bytes=mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs=0.99)
top_counts <- select(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
Vies(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs=0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count,-grade)
students2
res <- gather(students2, key, value)
res <- gather(students2, key, value, -grade)
res <- gather(students2, sex_class, count, -grade)
res
? separate
separate(res, col=sex_class, into=c("sex","class"))
submit()
students3
?gather
submit()
?spread
submit()
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status="passed")
passed <- mutate(faileded, status="failed")
passed <- mutate(failed, status="failed")
failed <- mutate(failed, status="failed")
bind_rows(passed, failed)
sat
?separate
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_dat <- today()
this_day
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_minute)
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms("2014-08-23 17:23:02")
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, minute = minute(now()), second = second(now())
)
this_moment <- update(this_moment, minute = minute(now()), second = second(now()))
update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
?now
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart = update(depart, hours = 17, minutes = 34)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15)+minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time <- mdy("June-17-2008", tz="Singapore")
last_time
last_time <- mdy("06-17-2008", tz="Singapore")
last_time
last_time <- mdy("06172008", tz="Singapore")
last_time
last_time <- ymd("2008-06-17", tz="Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
